{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity CarND Term 1 - Project 1 - Lane Finding\n",
    "***\n",
    "* ibalpowr@gmail.com\n",
    "* Jan'17 cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir(\"test_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define converting function ... from rgb to gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set kernel size 3x3 for blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up thresholds for canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_threshold = 100\n",
    "low_threshold = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define canny edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define polygon's vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vertices = np.array([[(30, 540), (450, 320), (500,320), (930,540)]],\n",
    "                   dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Region of Interest (ROI) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ROI (img, vertices):\n",
    "\n",
    "    # 1st create a same size empty mask as the input image\n",
    "    mask = np.zeros_like(img, dtype=img.dtype)\n",
    "    \n",
    "    # 2nd since the bitwise is an \"and\" operator,\n",
    "    # the polygon color is white, i.e. all 1's\n",
    "    polygon_color = 255\n",
    "    \n",
    "    # 3rd place polygon into the mask\n",
    "    cv2.fillPoly(mask, vertices, polygon_color)\n",
    "    \n",
    "    # 4th bitwise image and the mask\n",
    "    img_masked = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    return img_masked\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up parameters for opencv2 hough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# five hough transform parameters for cv2.HoughLinesP()\n",
    "\n",
    "rho = 1 \n",
    "theta = np.pi/180 \n",
    "threshold = 50 \n",
    "min_line_length = 1   \n",
    "max_line_gap = 3000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a lines_slopes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lines_slopes(lines):\n",
    "    slopes = []\n",
    "    for i in range(len(lines)):\n",
    "        slopes.append((lines[i,0,3]-lines[i,0,1])/\n",
    "                      (lines[i,0,2]-lines[i,0,0] + \n",
    "                       np.random.normal(0,1e-9)))\n",
    "    slopes_array=np.array(slopes).astype(np.float32)\n",
    "    slopes_array=np.reshape(slopes_array, (slopes_array.shape[0],1))\n",
    "    lines_array=np.reshape(lines,(lines.shape[0],4))\n",
    "    lines_slopes = np.hstack([lines_array,slopes_array])\n",
    "    lines_slopes = np.reshape(lines_slopes, (lines_slopes.shape[0],1,5))\n",
    "    new_lines_slopes = lines_slopes[((lines_slopes[:,:,4] >= 0.5) \n",
    "                                 & (lines_slopes[:,:,4] <= 0.8)) | \n",
    "                                ((lines_slopes[:,:,4] >= -0.85) \n",
    "                                 & (lines_slopes[:,:,4] <= -0.55))]\n",
    "    new_lines_slopes = np.reshape(new_lines_slopes, \n",
    "                                  (new_lines_slopes.shape[0],1,5))\n",
    "    new_lines_slopes = new_lines_slopes.astype(np.uint16)\n",
    "    return new_lines_slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a superimpose function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def superimpose (lines, img):\n",
    "    line_img = np.zeros((img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2,slope in line:\n",
    "            cv2.line(line_img, (x1, y1), (x2, y2), [255, 0, 0], 2)\n",
    "    new_img = cv2.addWeighted(line_img, 0.4, img, 1, 0)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "for i in range(len(files)):\n",
    "    image = mpimg.imread('test_images/' + files[i])\n",
    "    image_gray = grayscale(image)\n",
    "    image_gray_3x3 = cv2.GaussianBlur(image_gray, \n",
    "                                    (kernel_size, kernel_size), 0)\n",
    "    edges = canny(image_gray_3x3, low_threshold, high_threshold)\n",
    "    edges_masked = ROI(edges, vertices)\n",
    "    lines = cv2.HoughLinesP(edges_masked, rho, theta, threshold, \n",
    "                          np.array([]), min_line_length, max_line_gap)\n",
    "    lines_slopes = find_lines_slopes(lines)\n",
    "    new_image = superimpose(lines_slopes,image)\n",
    "    mpimg.imsave('test_images/'+files[i]+'.png', new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "def process_image(image):\n",
    "    image_gray = grayscale(image)\n",
    "    image_gray_3x3 = cv2.GaussianBlur(image_gray, \n",
    "                                    (kernel_size, kernel_size), 0)\n",
    "    edges = canny(image_gray_3x3, low_threshold, high_threshold)\n",
    "    edges_masked = ROI(edges, vertices)\n",
    "    lines = cv2.HoughLinesP(edges_masked, rho, theta, threshold, \n",
    "                          np.array([]), min_line_length, max_line_gap)\n",
    "    lines_slopes = find_lines_slopes(lines)\n",
    "    new_image = superimpose(lines_slopes,image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_output = 'yellow.mp4'\n",
    "clip1 = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_output = 'curve.mp4'\n",
    "clip1 = VideoFileClip(\"challenge.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
